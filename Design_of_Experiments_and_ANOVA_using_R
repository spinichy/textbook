##### part 1 -----------------------------------------------------------------------------------------------------------------------

##t-test

#Data Input
male <- c(327, 291, 323, 284, 305)
female <- c(308, 324, 353, 344, 341)

#H0: Variances are equal
var.test(male, female) #p-value = 0.9154

#Using Welch's t-test by default (var.equal = FALSE)
test_result <- t.test(male, female, var.equal = TRUE, alternative = "two.sided")
test_result #p-value = 0.04329: reject H0


##Anova - 2 variables
# 1. Data Input
male <- c(327, 291, 323, 284, 305)
female <- c(308, 324, 353, 344, 341)

# 2. Create Data Frame (Required for ANOVA)
scores <- c(male, female)
gender <- rep(c("Male", "Female"), each = 5)
df <- data.frame(gender, scores)

# 3. Perform ANOVA
anova_result <- aov(scores ~ gender, data = df)

# 4. View Results (Summary table)
summary(anova_result)

#verification
total_mean <- mean(df$scores)
group_mean <- aggregate(scores ~ gender, data = df, FUN = 'mean')
group_mean_Female <- group_mean %>% 
  filter(gender == 'Female') %>% 
  select(scores) %>% 
  as.numeric()
group_mean_Male <- group_mean %>% 
  filter(gender == 'Male') %>% 
  select(scores) %>% 
  as.numeric()

n_male <- length(male)
n_female <- length(female)

SST <- sum( (df$scores - total_mean)^2 )

SSR <- sum( n_female*(group_mean_Female - total_mean)^2 + 
              n_male*(group_mean_Male - total_mean)^2 )
SSE <- sum( (female - group_mean_Female)^2 ) + sum( (male - group_mean_Male)^2 )
MSR <- SSR/(2-1)
MSE <- SSE/(n_male - 1 + n_female - 1)

F_value <- MSR/MSE
pf(q = F_value, df1 = 1, df2 = 8, lower.tail = FALSE)


##Anova - 3 variables


# 1. Data Setup (Different sample sizes for each group)
# male (n=5), female (n=4), other (n=6)
male   <- c(327, 291, 323, 284, 305)
female <- c(308, 324, 353, 344)
other  <- c(315, 330, 310, 320, 325, 318)

# 2. Data Transformation
# Combine all scores
all_scores <- c(male, female, other)

# Create grouping labels corresponding to the number of data points in each group
group_labels <- c(rep("Male", length(male)), 
                  rep("Female", length(female)), 
                  rep("Other", length(other)))

# Create a data frame
df_unbalanced <- data.frame(
  group = factor(group_labels),
  score = all_scores
)

# 3. Check sample size for each group
table(df_unbalanced$group)

# 4. Perform One-way ANOVA  
# R's aov() handles unbalanced data using Type I Sum of Squares by default
anova_model <- aov(score ~ group, data = df_unbalanced)

# 5. Check ANOVA Summary Table
summary(anova_model)

# 6. Post-hoc Analysis (Tukey's HSD)
# TukeyHSD in R automatically adjusts for unequal sample sizes (Tukey-Kramer method)
tukey_result <- TukeyHSD(anova_model)
print(tukey_result)

# 7. Visualization
boxplot(score ~ group, data = df_unbalanced,
        main = "Unbalanced ANOVA: Score Comparison",
        xlab = "Group (Different Sample Sizes)",
        ylab = "Score",
        col = c("lightpink", "lightblue", "lightgreen"))


## exercise

##1.1 - 1


# 1. Load required libraries
library(sasLM)
library(ggplot2)

# 2. Data Preparation
# Load bondreturn dataset: Returns of bonds according to their ratings
sasLM::bondreturn

# 3. Exploratory Data Analysis (EDA)
# Check the internal structure and statistical summary
str(bondreturn)
summary(bondreturn)

# Check sample sizes for each group (Verifying Unbalanced Design)
table(bondreturn$Bond)

# 4. Create Boxplot comparing 'bank' vs 'corp'
ggplot(bondreturn, aes(x = Bond, y = Return, fill = Bond)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +
  geom_jitter(width = 0.1, color = "black", alpha = 0.5) +
  theme_minimal() +
  labs(
    title = "Comparison of Bond Returns: Bank vs. Corporation",
    subtitle = "Yield analysis between different bond sectors",
    x = "Bond Type",
    y = "Return Rate (%)"
  ) +
  # Use exact level names. If levels are capitalized, use "Bank" and "Corp"
  # Alternatively, use scale_fill_brewer for automatic mapping
  scale_fill_brewer(palette = "Set2") + 
  theme(legend.position = "none")


##1.1 - 2


# 1. Load library and data
library(sasLM)
sasLM::bondreturn

# 2. Check group levels and sample size
# Verify that there are exactly two groups: 'bank' and 'corp'
table(bondreturn$Bond)

# 3. Check for Homogeneity of Variance (Levene's Test)
# This determines whether to use a standard t-test or Welch's t-test
var.test(Return ~ Bond, data = bondreturn) #p-value = 0.7939

# 4. Perform Independent t-test
# t.test() in R defaults to Welch's t-test (var.equal = FALSE)
# If variances are equal, set var.equal = TRUE
t_result <- t.test(Return ~ Bond, data = bondreturn, var.equal = TRUE)
print(t_result) #p-value = 0.04611


##1.1 - 3


# 1. Load Data
library(sasLM)
sasLM::bondreturn

# 2. Split Data by Group (bank vs corp)
# Extract 'Return' values for each group
group_bank <- bondreturn$Return[bondreturn$Bond == "Bank"]
group_corp <- bondreturn$Return[bondreturn$Bond == "Corp"]

# 3. Calculate Basic Statistics (n, Mean, Variance)
n1 <- length(group_bank)        # Sample size of group 1
n2 <- length(group_corp)        # Sample size of group 2

mean1 <- mean(group_bank)       # Mean of group 1
mean2 <- mean(group_corp)       # Mean of group 2

var1 <- var(group_bank)         # Variance of group 1
var2 <- var(group_corp)         # Variance of group 2

# 4. Calculate Pooled Variance (Sp^2)
# This is used when assuming equal variances
sp2 <- ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)

# 5. Calculate t-statistic
# Formula: (Mean1 - Mean2) / sqrt(Sp^2 * (1/n1 + 1/n2))
se_diff <- sqrt(sp2 * (1/n1 + 1/n2))
t_val <- (mean1 - mean2) / se_diff

# 6. Calculate Degrees of Freedom (df) and p-value
df <- n1 + n2 - 2
# Two-tailed p-value using the t-distribution
p_val <- 2 * pt(abs(t_val), df, lower.tail = FALSE)

# 7. Print Results
cat("--- Manual t-test Results ---\n")
cat("t-statistic:", t_val, "\n")
cat("Degrees of Freedom:", df, "\n")
cat("p-value:", p_val, "\n")

# 8. Verification
# Compare with the built-in t.test function
t.test(Return ~ Bond, data = bondreturn, var.equal = TRUE)


##1.1 - 4


# 1. Load library and data
library(sasLM)
sasLM::bondreturn

# 2. Check group levels and sample size
# Verify that there are exactly two groups: 'bank' and 'corp'
table(bondreturn$Bond)

# 3. Check for Homogeneity of Variance (Levene's Test)
# This determines whether to use a standard t-test or Welch's t-test
var.test(Return ~ Bond, data = bondreturn) #p-value = 0.7939

# 4. Perform Independent t-test
t_result <- t.test(Return ~ Bond, 
                   data = bondreturn, 
                   var.equal = TRUE,              # Based on var.test p-value (0.7939)
                   alternative = "greater")          # Testing if bank > corp (i.e., bank - corp > 0)
print(t_result)


##1.1 - 5


# 1. Load library and data
library(sasLM)
sasLM::bondreturn

# 2. Fit the ANOVA model
# Dependent variable: Return, Independent variable: Bond
# Null Hypothesis (H0): Mean returns of 'bank' and 'corp' are equal
anova_model <- aov(Return ~ Bond, data = bondreturn)

# 3. Display the ANOVA table
# Check 'Pr(>F)' for statistical significance
summary(anova_model)

# 4. Check for Group Means
# Provides mean values for each group to understand the direction of difference
model.tables(anova_model, type = "means")

t_result$statistic^2 #5.179293 



##1.2, ##1.3


# 1. Load data
library(sasLM)
sasLM::bondreturn

# 2. Original ANOVA
# Testing original Return values
model_orig <- aov(Return ~ Bond, data = bondreturn)
summary(model_orig)

# 3. ANOVA with Constant Added (Return + 100)
# Location shift: Means change, but variances stay the same
model_add <- aov(I(Return + 100) ~ Bond, data = bondreturn)
summary(model_add)

# 4. ANOVA with Constant Multiplied (Return * 10)
# Scaling: Both MS_between and MS_within are scaled by 10^2
model_mul <- aov(I(Return * 10) ~ Bond, data = bondreturn)
summary(model_mul)


##1.5


# 1. Load the required library and dataset
library(sasLM)
sasLM::bulblife
# 2. Inspect the data structure
# The dataset contains 'Product' (Group) and 'Duration' (Response variable)
str(bulblife)
table(bulblife$Product)

# 3. Perform One-way ANOVA
# Null Hypothesis (H0): There is no difference in the mean duration between Product A and B.
# Alternative Hypothesis (H1): There is a significant difference in the mean duration.
fit <- aov(Duration ~ Product, data = bulblife)

# 4. Display the ANOVA table
# Check the p-value (Pr(>F)) to determine statistical significance
summary(fit)

# 5. Calculate group means
# This shows the average duration for each product type
model.tables(fit, type = "means")


# 6. Visualization without Warnings
# We map colors specifically to 'A' and 'B' to match the 'Product' levels
ggplot(bulblife, aes(x = Product, y = Duration, fill = Product)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +
  geom_jitter(width = 0.1, color = "black", alpha = 0.5) +
  scale_fill_manual(values = c("A" = "#69b3a2", "B" = "#404080")) +
  theme_minimal() +
  labs(
    title = "Analysis of Bulb Duration",
    subtitle = "p-value = 0.121 (Not Significant)",
    x = "Product Type",
    y = "Duration"
  ) +
  theme(legend.position = "none")



##### part 2 -----------------------------------------------------------------------------------------------------------------------

#example

#simple-linear regression
library(tidyverse)
library(sasLM)
str(simxy1)

lm_simxy1 <- lm(Y ~ X, data = simxy1)
summary(lm_simxy1)

windows()
pB(Y ~ X, Data = simxy1)


#simple-linear regression - visualization
# 1. Check data and create a model
library(sasLM)
data <- simxy1
lm_model <- lm(Y ~ X, data = data)

# 2. Generate sorted X values for smooth interval lines
new_x <- seq(min(data$X), max(data$X), length.out = 100)

# 3. Calculate Confidence and Prediction intervals
conf_interval <- predict(lm_model, newdata = data.frame(X = new_x), interval = "confidence")
pred_interval <- predict(lm_model, newdata = data.frame(X = new_x), interval = "prediction")

# 4. Draw basic scatter plot
windows()
plot(data$X, data$Y, 
     pch = 16,               # Point character (filled circle)
     col = "gray",           # Point color
     main = "Simple Linear Regression (Base R Plot)",
     xlab = "X", ylab = "Y",
     ylim = c(-2, 10),       # Set y-axis limits from -2 to 10
     yaxt = "n")             # Suppress default y-axis to customize ticks

# Add custom y-axis with an interval of 2
axis(2, at = seq(-2, 10, by = 2))

# 5. Add regression line
abline(lm_model, col = "blue", lwd = 2)

# 6. Add Confidence Interval (Blue dashed lines)
lines(new_x, conf_interval[, "lwr"], col = "blue", lty = 2)
lines(new_x, conf_interval[, "upr"], col = "blue", lty = 2)

# 7. Add Prediction Interval (Red dashed lines)
lines(new_x, pred_interval[, "lwr"], col = "red", lty = 2)
lines(new_x, pred_interval[, "upr"], col = "red", lty = 2)

# 8. Add legend
legend("bottomright", 
       legend = c("Regression Line", "95% Conf. Int", "95% Pred. Int"),
       col = c("blue", "blue", "red"), 
       lty = c(1, 2, 2), 
       lwd = c(2, 1, 1))


#simple-linear regression - ANOVA
anova(lm_simxy1)
14.4/(14.4 + 2.1)


## exercise

##2.1 

# Line 1: Points (2, 0) and (5, 5)
x1 <- c(2, 5)
y1 <- c(0, 5)

# Line 2: Points (-2, 1) and (6, 6)
x2 <- c(-2, 6)
y2 <- c(1, 6)

# Function to calculate slope and intercept
get_line <- function(x, y) {
  m <- (y[2] - y[1]) / (x[2] - x[1])
  b <- y[1] - m * x[1]
  return(c(m, b))
}

# Calculate parameters
line1_res <- get_line(x1, y1)
line2_res <- get_line(x2, y2)

# Create label strings for the legend
label1 <- paste0("Line 1: y = ", round(line1_res[1], 3), "x + ", round(line1_res[2], 3))
label2 <- paste0("Line 2: y = ", round(line2_res[1], 3), "x + ", round(line2_res[2], 3))

# Print equations to console (as requested)
cat("Line 1 Equation: y =", round(line1_res[1], 3), "x +", round(line1_res[2], 3), "\n")
cat("Line 2 Equation: y =", round(line2_res[1], 3), "x +", round(line2_res[2], 3), "\n")

# Visualization
plot(NULL, xlim = c(-3, 7), ylim = c(-2, 7), 
     xlab = "X-axis", ylab = "Y-axis", main = "Lines with Equations in Legend")

# Plot Line 1
abline(a = line1_res[2], b = line1_res[1], col = "red", lwd = 2)
points(x1, y1, col = "red", pch = 19)

# Plot Line 2
abline(a = line2_res[2], b = line2_res[1], col = "blue", lwd = 2, lty = 2)
points(x2, y2, col = "blue", pch = 17)

# Add Legend with Equations
legend("topleft", legend = c(label1, label2),
       col = c("red", "blue"), lty = c(1, 2), pch = c(19, 17), cex = 0.8)

grid()


##2.3


# Create the data frame
df <- data.frame(
  X = c(0.5, 1.0, 1.5),
  Y = c(2, 1, 3)
)

# Define parameters for Line A and B
m_a <- -1; b_a <- 3
m_b <- 3;  b_b <- -1

# Calculate Sum of Squared Errors (SSE)
pred_a <- m_a * df$X + b_a
sse_a  <- sum((df$Y - pred_a)^2)

pred_b <- m_b * df$X + b_b
sse_b  <- sum((df$Y - pred_b)^2)

# Linear Regression (Best fit line)
fit <- lm(Y ~ X, data = df)
sse_reg <- sum(residuals(fit)^2)

# Visualization setup
par(mar = c(5, 4, 4, 2))

# Plot the points
plot(df$X, df$Y, 
     pch = 19, 
     xlim = c(0, 2), 
     ylim = c(-1, 5), 
     xlab = "X Label", 
     ylab = "Y Label", 
     main = "Error Analysis and Regression Line")

# Restrict line drawing to the plot area
clip(0, 2, -1, 5)

# 1. Plot Line A & B as solid lines (lty = 1)
abline(a = b_a, b = m_a, col = "red", lwd = 2, lty = 1)
abline(a = b_b, b = m_b, col = "blue", lwd = 2, lty = 1)

# 2. Plot Regression Line as a dashed line (lty = 2)
abline(fit, col = "darkgreen", lwd = 2, lty = 2)

# Add Legend with adjusted spacing and line types
legend("topleft", 
       inset = c(0.05, 0.05), # Move further from the edge to prevent clipping
       legend = c("Data Points", 
                  paste("Line A (SSE:", sse_a, ")"), 
                  paste("Line B (SSE:", sse_b, ")"),
                  paste("Regression (SSE:", round(sse_reg, 2), ")")),
       col = c("black", "red", "blue", "darkgreen"), 
       pch = c(19, NA, NA, NA), 
       lty = c(NA, 1, 1, 2),  # Match the line styles: Solid, Solid, Dashed
       cex = 0.8,             # Font size
       y.intersp = 1.5,       # Increase vertical space between legend items
       bg = "white",          # White background to cover grid lines
       box.col = "black")     # Clear border color

# Add background grid
grid()


##2.4


# 1. Data Frame Setup
df <- data.frame(
  Year = c(1980, 1982, 1985, 1987, 1989),
  X = c(430, 395, 360, 270, 180),
  Y = c(40, 60, 80, 88, 98)
)

# 2. Simple Linear Regression
model <- lm(Y ~ X, data = df)

# 3. Visualization Setup
# Increase right margin slightly to ensure legend has enough space
par(mar = c(5, 4, 4, 3))

# Define axis limits for consistency
x_min <- 150; x_max <- 450
y_min <- 30;  y_max <- 110

# Plot the scatter points
plot(df$X, df$Y,
     pch = 19,
     col = "blue",
     xlim = c(x_min, x_max),
     ylim = c(y_min, y_max),
     main = "Error Analysis and Regression Line",
     xlab = "Independent Variable (X)",
     ylab = "Dependent Variable (Y)")

# Add background grid
grid()

# 4. Restrict Line Drawing to the Plot Area
# Ensures abline does not leak outside the axes
clip(x_min, x_max, y_min, y_max)

# Add the regression line (Dashed)
abline(model, col = "red", lwd = 2, lty = 2)

# 5. Adjusted Legend to Prevent Clipping
# Reset clip to allow drawing the legend properly if needed
do.call(clip, as.list(par("usr"))) 

legend("topright",
       # inset: move legend away from the top-right corner edges
       inset = c(0.05, 0.05), 
       legend = c("Data Points", "Regression Line (Dashed)"),
       col = c("blue", "red"),
       pch = c(19, NA),
       lty = c(NA, 2),
       lwd = c(NA, 2),
       cex = 0.8,           # Font size
       y.intersp = 1.5,      # Vertical spacing between items
       bg = "white",         # White background to prevent grid overlap
       box.col = "black")    # Explicit border to see the legend clearly

# 6. Statistical Outputs (Console)
print("--- Linear Regression Summary ---")
print(summary(model))

print("--- ANOVA Table ---")
print(anova(model))

model_anova <- anova(model)
model_anova$`Sum Sq`[1] #SSR
model_anova$`Sum Sq`[2] #SSE




#exercise 3.4 (1)

# 1. Data Input
male <- c(327, 291, 323, 284, 305)
female <- c(308, 324, 353, 344, 341)

# Combine into a data frame
# English Comment: Create a categorical variable for gender (0 for male, 1 for female)
value <- c(male, female)
gender <- factor(x = c(rep("Male", 5), rep("Female", 5)))
gender <- ifelse(gender == "Male", -1, 1)
df <- data.frame(gender, value)

# 3. Simple Regression Analysis
# English Comment: Fit a linear model. Female is usually the reference group by default (alphabetical).
fit_lm <- lm(value ~ gender, data = df)
cat("\n--- Regression Analysis Summary ---\n")
print(summary(fit_lm))

# 4. Analysis of Variance (ANOVA)
# English Comment: Perform ANOVA to see the group differences.
fit_aov <- aov(value ~ gender, data = df)
cat("\n--- ANOVA Table ---\n")
print(summary(fit_aov))


##### part 3 -----------------------------------------------------------------------------------------------------------------------


#exercise 3.4 (2)


# Data Input
male_val <- c(327, 291, 323, 284, 305)
female_val <- c(308, 324, 353, 344, 341)

# Case 1: If original x was -1 and 1
m <- -1
l <- 2
x_orig <- c(-1, 1) # Male, Female
x_star <- (x_orig - m) / l
# Result will be 0, 1

# Case 2: Mapping categorical data to 0 and 1 in a model
# English Comment: Create a dummy variable where Male = 0 and Female = 1
gender_factor <- factor(c(rep("Male", 5), rep("Female", 5)), levels = c("Male", "Female"))
x_dummy <- as.numeric(gender_factor) - 1 

# English Comment: This x_dummy will be 0 for Male and 1 for Female.
print(x_dummy)


#exercise 3.4 (3)
df_2 <- data.frame(x_dummy, value)
fit_lm_2 <- lm(value ~ x_dummy,, data = df_2)
fit_aov_2 <- aov(value ~ x_dummy,, data = df_2)

summary(fit_lm_2)
summary(fit_aov_2)


##### part 4 -----------------------------------------------------------------------------------------------------------------------


